{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import json\n",
    "import requests\n",
    "from transformers import LayoutLMModel\n",
    "from pytorch_lightning import LightningModule\n",
    "import torch.nn as nn\n",
    "from infer.model.loss import BboxLoss\n",
    "from infer.model.spade_model import RelationTagger\n",
    "import json\n",
    "\n",
    "# jsonfile =  json.load(open('./notebook/json_file/cccd_test.jsonl')) \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/layoutlm-base-uncased\")\n",
    "def get_bbox(jsonl_file):\n",
    "    w = jsonl_file['img_sz']['width']\n",
    "    h = jsonl_file['img_sz']['height']\n",
    "    bboxes = [[ int(x[0][0]*1000/w),int(x[0][1]*1000/h) ,int(x[2][0]*1000/w),int(x[2][1]*1000/h)] for x in jsonl_file['coord']]\n",
    "    # return  torch.tensor(bboxes)\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, torch.Size([1, 127]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataModel.datamd_ import DpDataSet\n",
    "import numpy as np\n",
    "data = DpDataSet('./notebook/json_file/test_shuffe.jsonl')\n",
    "\n",
    "data[0]['maps_tensor'].shape, \n",
    "\n",
    "i = 0\n",
    "for item in data[0]['maps']:\n",
    "    for idx in item: \n",
    "        i = i + 1\n",
    "i, data[0]['maps_tensor'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = np.array(maps.cpu())\n",
    "# m = m.tolist()\n",
    "# box_index =  np.unique(m).tolist()\n",
    "# [[item]*m.count(item) for item in box_index]\n",
    "# input_ids.shape\n",
    "from functools import lru_cache\n",
    "@lru_cache\n",
    "def load_model():\n",
    "\n",
    "    return LayoutLMModel.from_pretrained(\n",
    "                \"microsoft/layoutlm-base-uncased\", local_files_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/layoutlm-base-uncased were not used when initializing LayoutLMModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing LayoutLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LayoutLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "model =  load_model()\n",
    "# maps\n",
    "input_ids = data[0]['input_ids']\n",
    "bbox = data[0]['bbox']\n",
    "attention_mask = data[0]['attention_mask']\n",
    "token_type_ids = data[0]['token_type_ids']\n",
    "maps = data[0]['maps']\n",
    "maps_tensor = data[0]['maps_tensor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(input_ids=input_ids,bbox=bbox,attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "outputs.last_hidden_state.shape\n",
    "\n",
    "reduce_size = 256\n",
    "\n",
    "ln = nn.Linear(model.config.hidden_size, reduce_size)\n",
    "\n",
    "last_hidden_state = ln(outputs.last_hidden_state)\n",
    "last_hidden_state.shape\n",
    "\n",
    "zeros_temp = torch.zeros(reduce_size)\n",
    "# m = nn.BatchNorm1d(last_hidden_state.shape[1] , affine=False)\n",
    "# last_hidden_state, m (last_hidden_state).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings\n",
    " \n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "r = ['aăâbcdđeêghiklmnoôơpqrstuưvxy']\n",
    "# model = Word2Vec(sentences=data[0]['text'], vector_size=100, window=5, min_count=1, workers=4,  sg= 1)\n",
    "\n",
    "\n",
    "srt = [['hooman', 'interface', 'computer'],\n",
    "  ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
    "  ['eps', 'user', 'interface', 'system'],\n",
    "  ['system', 'human', 'system', 'eps'],\n",
    "  ['user', 'response', 'time'],\n",
    "  ['trees'],\n",
    "  ['graph', 'trees'],\n",
    "  ['graph', 'minors', 'trees'],\n",
    "  ['graph', 'minors', 'survey']]\n",
    "\n",
    "model = Word2Vec(sentences=[[item] for item in data[0]['text']] , vector_size=100, window=5, min_count=1, workers=4,  sg= 1)\n",
    "\n",
    "# common_texts\n",
    "\n",
    "len(model.wv) #, common_texts\n",
    "# model.wv['hooman']\n",
    "\n",
    "[[item] for item in data[0]['text']] , data[0]['text'],len(data[0]['text']) \n",
    "\n",
    "\n",
    "def wordemd_loss (text):\n",
    "  model = Word2Vec(sentences=[[item] for item in text] , vector_size=100, window=5, min_count=1, workers=4,  sg= 1)\n",
    "  return model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08055088"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import linalg as LA\n",
    "\n",
    "b = 0 + wordemd_loss(data[0]['text'])[0] +  wordemd_loss(data[0]['text'])[1]\n",
    "\n",
    "LA.norm(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def tranfer_maps(maps: Tensor):\n",
    "#     m = []\n",
    "#     maps = torch.squeeze(maps, 0)\n",
    "#     uniq, count= maps.unique(return_counts=True)\n",
    "#     for i in range(len(count)):\n",
    "#         m.append(torch.stack([uniq[i]]*count[i]))\n",
    "#     return m\n",
    "\n",
    "\n",
    "def reduce_shape_old(last_hidden_state, maps):\n",
    "        device = last_hidden_state.device\n",
    "        reduce = []\n",
    "        for g_token in maps:\n",
    "            ten = zeros_temp.to(device)\n",
    "            for ele in g_token:\n",
    "                # print(g_token[0],'-----')\n",
    "                ten += last_hidden_state[0][g_token[0]]\n",
    "                # print(ele,'----')\n",
    "            ten = ten/len(g_token)\n",
    "            # print(len(g_token))\n",
    "            reduce.append(ten)\n",
    "        reduce = torch.stack(reduce).to(device)\n",
    "        return reduce\n",
    "\n",
    "\n",
    "\n",
    "reduce_old = reduce_shape_old(last_hidden_state, maps)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rel_s = RelationTagger(\n",
    "            hidden_size=reduce_size,\n",
    "            n_fields=3,\n",
    "        )\n",
    "\n",
    "S = rel_s(reduce_old.unsqueeze(0))\n",
    "# tranfer_maps(maps)\n",
    "# maps = \n",
    "# reduce_shape(last_hidden_state, tranfer_maps(maps) ) \n",
    "reduce_old.shape, np.shape(maps), S.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reduce_shape(last_hidden_state, maps: Tensor):\n",
    "    maps = torch.squeeze(maps, 0)\n",
    "    uniq, count= maps.unique(return_counts=True)\n",
    "    device = last_hidden_state.device\n",
    "    reduce = []\n",
    "    for idx,  g_token in enumerate (uniq):\n",
    "        ten = zeros_temp.to(device)\n",
    "        for j in range (count[idx]):\n",
    "            # print(g_token.numpy(),'-----')\n",
    "            ten += last_hidden_state[0][g_token.numpy()]\n",
    "        # print(g_token, idx)\n",
    "        ten = ten/count.detach().numpy()[idx]\n",
    "        # print(count.detach().numpy()[idx])\n",
    "        reduce.append(ten)\n",
    "    reduce = torch.stack(reduce).to(device)\n",
    "    return reduce\n",
    "reduce = reduce_shape(last_hidden_state, maps_tensor)\n",
    "# # maps\n",
    "\n",
    "# with torch.no_grad():\n",
    "#   b =  torch.mean(reduce -reduce_old)\n",
    "#   print(b)\n",
    "\n",
    "reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tranfer_maps(maps: Tensor):\n",
    "    m = []\n",
    "    maps = torch.squeeze(maps, 0)\n",
    "    uniq, count= maps.unique(return_counts=True)\n",
    "    for i in range(len(count)):\n",
    "        m.append(torch.stack([uniq[i]]*count[i]).tolist())\n",
    "    return m\n",
    "\n",
    "\n",
    "\n",
    "a = reduce_shape_old(last_hidden_state, maps) - reduce_shape_old(last_hidden_state,maps )\n",
    "with torch.no_grad():\n",
    "    \n",
    "    print(torch.mean(a))\n",
    "\n",
    "# tranfer_maps(maps_tensor), maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Learnable Parameters\n",
    "# m = nn.BatchNorm2d(100)\n",
    "# Without Learnable Parameters\n",
    "m = nn.BatchNorm2d(100, affine=False)\n",
    "input = torch.randn(20, 100, 35, 45)\n",
    "output = m(input)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %reload_ext autoreload\n",
    "from models.layout_parsing import LitBaseParsing\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from models.base import  LitLayoutParsing\n",
    "model = LitBaseParsing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# totalGraph =  model(input_ids, attention_mask, token_type_ids, bbox,maps)\n",
    "\n",
    "# totalGraph.shape\n",
    "dummy_input = torch.zeros(3,126)\n",
    "dummy_input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_input = torch.zeros_like(input_ids).cuda()\n",
    "# dummy_boxes = torch.zeros_like(bbox).cuda()\n",
    "# dummy_maps = torch.zeros_like(maps).cuda()\n",
    "import torch\n",
    "dummy_input = torch.zeros(1,196).cuda()\n",
    "dummy_boxes = torch.zeros(1,196,4).cuda()\n",
    "dummy_maps = torch.zeros(1,196).cuda()\n",
    "# totalGraph[0].shape\n",
    "# S = totalGraph[0].unsqueeze(0)\n",
    "# G = totalGraph[1].unsqueeze(0)\n",
    "# dummy_maps.shape\n",
    "# dummy_maps.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "providers = [\n",
    "            # 'TensorrtExecutionProvider',\n",
    "                     'CUDAExecutionProvider',\n",
    "                     'CPUExecutionProvider']\n",
    "\n",
    "ort_sess = ort.InferenceSession(\n",
    "                                path_or_bytes = 'resources/onnx/LitLP_06-03-2023_18-46-25_fp32.onnx'\n",
    "                                , providers= providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = ort_sess.get_inputs()\n",
    "# output_name = ort_sess.get_outputs()[0].name\n",
    "input_name[3].name\n",
    "\n",
    "\n",
    "# outputs = ort_sess.run(None, \n",
    "#                         {\n",
    "#                             'input_1': input_ids.numpy()\n",
    "#                             'input_2': input_ids.numpy()\n",
    "#                             'input_3': input_ids.numpy()\n",
    "#                             'input_4': input_ids.numpy()\n",
    "#                             'input_5': input_ids.numpy()\n",
    "#                         }\n",
    "#                         )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
