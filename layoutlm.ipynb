{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/layoutlm-base-uncased were not used when initializing LayoutLMModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing LayoutLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LayoutLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LayoutLMConfig {\n",
       "  \"_name_or_path\": \"microsoft/layoutlm-base-uncased\",\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_2d_position_embeddings\": 1024,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"layoutlm\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.24.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, BatchEncoding, BertModel,LayoutLMModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/layoutlm-base-uncased\")\n",
    "model = LayoutLMModel.from_pretrained(\"microsoft/layoutlm-base-uncased\")\n",
    "config = AutoConfig.from_pretrained(\"microsoft/layoutlm-base-uncased\")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "# result = json.load(open('./data/processed/train/huy.jsonl'))\n",
    "# result = json.load(open('data/processed/train/trinh.jsonl'))\n",
    "# result = json.load(open('data/processed/train/kha.jsonl'))\n",
    "result = json.load(open('data/processed/train/huong.jsonl'))\n",
    "# result = json.load(open('data/processed/trinh.jsonl'))\n",
    "# result = json.load(open('data/processed/trinh.jsonl'))\n",
    "words = result['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = result['img_sz']['width']\n",
    "h = result['img_sz']['height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1060,  2050, 14684,  7570,  2072, 19710, 26478,  7570,  2050,\n",
       "         12835, 12995, 15125,  1102, 10085,  2079,  5001, 10722,  7658,  2232,\n",
       "          6887, 14194,  1011,  1011, 26478,  4907,  2064, 12731, 10085,  6390,\n",
       "          2683,  5718,  8889,  2692, 12740,  2620,  6021,  2061,  7570,  2702,\n",
       "          1024,  1011, 12436,  1045, 16215,  2072, 25283, 15876,  5063,  8254,\n",
       "          2232,  2676,  1013,  5840,  1013,  2722,  1011, 12835,  4710,  2084,\n",
       "          2290,  1010, 15125, 16371, 19710, 15125, 21025, 10448,  9543,  2232,\n",
       "          1024, 22035,  2278, 14841,  2818,  1024, 10861,  6887, 14194,  9152,\n",
       "         25311,  6887,  2080,  2084,  2232,  9152, 25311, 24110,  8026,  2232,\n",
       "          1010,  9152, 25311,  8026,  2232,  2053,  2072, 19817,  2226,  1102,\n",
       "         10441,  2072, 16215, 19098,  3070,  9152, 25311,  8026,  2232,  1010,\n",
       "         16215, 19098,  3070,  1010,  9152, 25311,  6887, 14194,  6887,  2080,\n",
       "          2084,  2232,  9152, 25311,  8026,  2232,  2522, 27699, 13012,  1102,\n",
       "          2063,  2676,  1013,  5840,  1013, 16798,  2475,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes = tuple([[ int(x[0][0]*1000/w),int(x[0][1]*1000/h) ,int(x[2][0]*1000/w),int(x[2][1]*1000/h)] for x in result['coord']])\n",
    "# bboxes = tuple(bboxes)\n",
    "\n",
    "\n",
    "# text label data_id coord\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1060,  2050, 14684,  7570,  2072, 19710, 26478,  7570,  2050,\n",
       "          12835, 12995, 15125,  1102, 10085,  2079,  5001, 10722,  7658,  2232,\n",
       "           6887, 14194,  1011,  1011, 26478,  4907,  2064, 12731, 10085,  6390,\n",
       "           2683,  5718,  8889,  2692, 12740,  2620,  6021,  2061,  7570,  2702,\n",
       "           1024,  1011, 12436,  1045, 16215,  2072, 25283, 15876,  5063,  8254,\n",
       "           2232,  2676,  1013,  5840,  1013,  2722,  1011, 12835,  4710,  2084,\n",
       "           2290,  1010, 15125, 16371, 19710, 15125, 21025, 10448,  9543,  2232,\n",
       "           1024, 22035,  2278, 14841,  2818,  1024, 10861,  6887, 14194,  9152,\n",
       "          25311,  6887,  2080,  2084,  2232,  9152, 25311, 24110,  8026,  2232,\n",
       "           1010,  9152, 25311,  8026,  2232,  2053,  2072, 19817,  2226,  1102,\n",
       "          10441,  2072, 16215, 19098,  3070,  9152, 25311,  8026,  2232,  1010,\n",
       "          16215, 19098,  3070,  1010,  9152, 25311,  6887, 14194,  6887,  2080,\n",
       "           2084,  2232,  9152, 25311,  8026,  2232,  2522, 27699, 13012,  1102,\n",
       "           2063,  2676,  1013,  5840,  1013, 16798,  2475,   102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'bbox': tensor([[[   0,    0,    0,    0],\n",
       "          [ 507,   44,  556,  103],\n",
       "          [ 507,   44,  556,  103],\n",
       "          [ 624,   43,  695,  101],\n",
       "          [ 558,   46,  619,  108],\n",
       "          [ 558,   46,  619,  108],\n",
       "          [ 808,   45,  887,  105],\n",
       "          [ 340,   49,  430,  109],\n",
       "          [ 437,   50,  507,  103],\n",
       "          [ 437,   50,  507,  103],\n",
       "          [ 699,   50,  802,  100],\n",
       "          [ 699,   50,  802,  100],\n",
       "          [ 892,   51,  966,   99],\n",
       "          [ 443,  104,  499,  165],\n",
       "          [ 443,  104,  499,  165],\n",
       "          [ 631,  107,  667,  159],\n",
       "          [ 499,  108,  546,  167],\n",
       "          [ 582,  110,  627,  159],\n",
       "          [ 703,  107,  782,  161],\n",
       "          [ 703,  107,  782,  161],\n",
       "          [ 789,  108,  860,  161],\n",
       "          [ 789,  108,  860,  161],\n",
       "          [ 549,  120,  579,  152],\n",
       "          [ 670,  124,  696,  151],\n",
       "          [ 654,  179,  802,  267],\n",
       "          [ 804,  180,  910,  269],\n",
       "          [ 395,  185,  496,  263],\n",
       "          [ 507,  184,  647,  265],\n",
       "          [ 507,  184,  647,  265],\n",
       "          [ 531,  279,  633,  352],\n",
       "          [ 531,  279,  633,  352],\n",
       "          [ 633,  276,  867,  355],\n",
       "          [ 633,  276,  867,  355],\n",
       "          [ 633,  276,  867,  355],\n",
       "          [ 633,  276,  867,  355],\n",
       "          [ 633,  276,  867,  355],\n",
       "          [ 462,  286,  531,  345],\n",
       "          [ 397,  307,  450,  362],\n",
       "          [ 335,  419,  372,  456],\n",
       "          [ 409,  419,  450,  456],\n",
       "          [ 409,  419,  450,  456],\n",
       "          [ 350,  456,  419,  493],\n",
       "          [ 374,  420,  404,  461],\n",
       "          [ 636,  421,  673,  469],\n",
       "          [ 592,  469,  651,  518],\n",
       "          [ 592,  469,  651,  518],\n",
       "          [ 492,  452,  588,  513],\n",
       "          [ 659,  460,  789,  510],\n",
       "          [ 659,  460,  789,  510],\n",
       "          [ 537,  530,  757,  595],\n",
       "          [ 537,  530,  757,  595],\n",
       "          [ 537,  530,  757,  595],\n",
       "          [ 537,  530,  757,  595],\n",
       "          [ 537,  530,  757,  595],\n",
       "          [ 537,  530,  757,  595],\n",
       "          [ 537,  530,  757,  595],\n",
       "          [ 143,  551,  179,  582],\n",
       "          [ 338,  545,  404,  592],\n",
       "          [ 338,  545,  404,  592],\n",
       "          [ 407,  547,  483,  600],\n",
       "          [ 407,  547,  483,  600],\n",
       "          [ 407,  547,  483,  600],\n",
       "          [ 485,  551,  536,  591],\n",
       "          [ 434,  616,  482,  666],\n",
       "          [ 721,  613,  779,  674],\n",
       "          [ 785,  617,  858,  671],\n",
       "          [ 339,  628,  384,  667],\n",
       "          [ 339,  628,  384,  667],\n",
       "          [ 389,  627,  434,  667],\n",
       "          [ 389,  627,  434,  667],\n",
       "          [ 389,  627,  434,  667],\n",
       "          [ 600,  625,  663,  672],\n",
       "          [ 600,  625,  663,  672],\n",
       "          [ 664,  629,  717,  675],\n",
       "          [ 664,  629,  717,  675],\n",
       "          [ 664,  629,  717,  675],\n",
       "          [ 337,  710,  387,  755],\n",
       "          [ 517,  704,  600,  765],\n",
       "          [ 517,  704,  600,  765],\n",
       "          [ 440,  704,  514,  765],\n",
       "          [ 440,  704,  514,  765],\n",
       "          [ 514,  765,  576,  827],\n",
       "          [ 514,  765,  576,  827],\n",
       "          [ 414,  765,  510,  827],\n",
       "          [ 414,  765,  510,  827],\n",
       "          [ 578,  765,  653,  827],\n",
       "          [ 578,  765,  653,  827],\n",
       "          [ 390,  711,  440,  762],\n",
       "          [ 656,  766,  737,  827],\n",
       "          [ 656,  766,  737,  827],\n",
       "          [ 656,  766,  737,  827],\n",
       "          [ 742,  767,  815,  826],\n",
       "          [ 742,  767,  815,  826],\n",
       "          [ 822,  767,  895,  826],\n",
       "          [ 822,  767,  895,  826],\n",
       "          [ 336,  833,  376,  872],\n",
       "          [ 336,  833,  376,  872],\n",
       "          [ 460,  827,  559,  888],\n",
       "          [ 460,  827,  559,  888],\n",
       "          [ 460,  827,  559,  888],\n",
       "          [ 460,  827,  559,  888],\n",
       "          [ 460,  827,  559,  888],\n",
       "          [ 380,  835,  459,  877],\n",
       "          [ 380,  835,  459,  877],\n",
       "          [ 380,  835,  459,  877],\n",
       "          [ 554,  893,  629,  958],\n",
       "          [ 554,  893,  629,  958],\n",
       "          [ 632,  893,  712,  958],\n",
       "          [ 632,  893,  712,  958],\n",
       "          [ 632,  893,  712,  958],\n",
       "          [ 559,  827,  697,  893],\n",
       "          [ 559,  827,  697,  893],\n",
       "          [ 559,  827,  697,  893],\n",
       "          [ 559,  827,  697,  893],\n",
       "          [ 702,  831,  775,  890],\n",
       "          [ 702,  831,  775,  890],\n",
       "          [ 783,  835,  861,  889],\n",
       "          [ 783,  835,  861,  889],\n",
       "          [ 488,  892,  551,  954],\n",
       "          [ 488,  892,  551,  954],\n",
       "          [ 388,  894,  486,  955],\n",
       "          [ 388,  894,  486,  955],\n",
       "          [ 719,  900,  792,  953],\n",
       "          [ 719,  900,  792,  953],\n",
       "          [ 796,  898,  871,  958],\n",
       "          [ 796,  898,  871,  958],\n",
       "          [  21,  938,   56,  981],\n",
       "          [  57,  938,   95,  985],\n",
       "          [  98,  939,  126,  983],\n",
       "          [ 129,  934,  307,  986],\n",
       "          [ 129,  934,  307,  986],\n",
       "          [ 129,  934,  307,  986],\n",
       "          [ 129,  934,  307,  986],\n",
       "          [ 129,  934,  307,  986],\n",
       "          [ 129,  934,  307,  986],\n",
       "          [ 129,  934,  307,  986],\n",
       "          [ 129,  934,  307,  986],\n",
       "          [1000, 1000, 1000, 1000]]]),\n",
       " 'maps': [[0],\n",
       "  [1, 1],\n",
       "  [2],\n",
       "  [3, 3],\n",
       "  [4],\n",
       "  [5],\n",
       "  [6, 6],\n",
       "  [7, 7],\n",
       "  [8],\n",
       "  [9, 9],\n",
       "  [10],\n",
       "  [11],\n",
       "  [12],\n",
       "  [13, 13],\n",
       "  [14, 14],\n",
       "  [15],\n",
       "  [16],\n",
       "  [17],\n",
       "  [18],\n",
       "  [19],\n",
       "  [20, 20],\n",
       "  [21, 21],\n",
       "  [22, 22, 22, 22, 22],\n",
       "  [23],\n",
       "  [24],\n",
       "  [25],\n",
       "  [26, 26],\n",
       "  [27],\n",
       "  [28],\n",
       "  [29],\n",
       "  [30, 30],\n",
       "  [31],\n",
       "  [32, 32],\n",
       "  [33, 33, 33, 33, 33, 33, 33],\n",
       "  [34],\n",
       "  [35, 35],\n",
       "  [36, 36, 36],\n",
       "  [37],\n",
       "  [38],\n",
       "  [39],\n",
       "  [40],\n",
       "  [41, 41],\n",
       "  [42, 42, 42],\n",
       "  [43, 43],\n",
       "  [44, 44, 44],\n",
       "  [45],\n",
       "  [46, 46],\n",
       "  [47, 47],\n",
       "  [48, 48],\n",
       "  [49, 49],\n",
       "  [50, 50],\n",
       "  [51],\n",
       "  [52, 52, 52],\n",
       "  [53, 53],\n",
       "  [54, 54],\n",
       "  [55, 55],\n",
       "  [56, 56, 56, 56, 56],\n",
       "  [57, 57, 57],\n",
       "  [58, 58],\n",
       "  [59, 59, 59],\n",
       "  [60, 60, 60, 60],\n",
       "  [61, 61],\n",
       "  [62, 62],\n",
       "  [63, 63],\n",
       "  [64, 64],\n",
       "  [65, 65],\n",
       "  [66, 66],\n",
       "  [67],\n",
       "  [68],\n",
       "  [69],\n",
       "  [70, 70, 70, 70, 70, 70, 70, 70],\n",
       "  [71]]}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def handel(word, coord, size):\n",
    "    w,h = size\n",
    "    normalized_word_boxes = tuple([[ int(x[0][0]*1000/w),int(x[0][1]*1000/h) ,int(x[2][0]*1000/w),int(x[2][1]*1000/h)] for x in coord])\n",
    "    encoding = tokenizer(\" \".join(words), return_tensors=\"pt\")\n",
    "    token_boxes = []\n",
    "    tokens = []\n",
    "    tokens = [tokenizer.cls_token] + tokens\n",
    "    i =0\n",
    "    maps = []\n",
    "    maps.extend([[i]])\n",
    "\n",
    "    for word, box in zip(words, normalized_word_boxes):\n",
    "        word_tokens = tokenizer.tokenize(word)\n",
    "        token_boxes.extend([box] * len(word_tokens))\n",
    "        tokens.extend(word_tokens)\n",
    "        i += 1\n",
    "        maps.extend([[i]*len(word_tokens)])\n",
    "\n",
    "    tokens += [tokenizer.sep_token]\n",
    "    maps.extend([[i+1]])\n",
    "\n",
    "    token_boxes = [[0, 0, 0, 0]] + token_boxes + [[1000, 1000, 1000, 1000]]\n",
    "\n",
    "    input_ids = encoding[\"input_ids\"]\n",
    "    attention_mask = encoding[\"attention_mask\"]\n",
    "    token_type_ids = encoding[\"token_type_ids\"]\n",
    "    bbox = torch.tensor([token_boxes])\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask,'token_type_ids':token_type_ids,'bbox':bbox , 'maps': maps}\n",
    "\n",
    "handel(words,result['coord'],(w,h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'x', '##a', 'chu', 'ho', '##i', 'viet', 'cong', 'ho', '##a', 'ng', '##hia', 'nam', 'đ', '##oc', 'do', 'lap', 'tu', 'han', '##h', 'ph', '##uc', '-', '-', 'cong', 'dan', 'can', 'cu', '##oc', '71', '##9', '07', '##00', '##0', '##40', '##8', '03', 'so', 'ho', 'ten', ':', '-', 'va', 'i', 'th', '##i', 'tran', 'hu', '##ong', 'sin', '##h', '27', '/', '04', '/', '1997', '-', 'ng', '##ay', 'than', '##g', ',', 'nam', 'nu', 'viet', 'nam', 'gi', '##oi', 'tin', '##h', ':', 'quo', '##c', 'ti', '##ch', ':', 'que', 'ph', '##uc', 'ni', '##nh', 'ph', '##o', 'than', '##h', 'ni', '##nh', 'quan', 'bin', '##h', ',', 'ni', '##nh', 'bin', '##h', 'no', '##i', 'tr', '##u', 'đ', '##oa', '##i', 'th', '##uo', '##ng', 'ni', '##nh', 'bin', '##h', ',', 'th', '##uo', '##ng', ',', 'ni', '##nh', 'ph', '##uc', 'ph', '##o', 'than', '##h', 'ni', '##nh', 'bin', '##h', 'co', 'gia', 'tri', 'đ', '##e', '27', '/', '04', '/', '202', '##2', '[SEP]']\n",
      "torch.Size([1, 138]) torch.Size([1, 138]) torch.Size([1, 138, 4]) torch.Size([1, 138]) (72,)\n",
      "torch.Size([1, 138, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-10fb1457c4bc>:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  print(input_ids.shape,attention_mask.shape,bbox.shape,token_type_ids.shape,np.array (maps).shape)\n"
     ]
    }
   ],
   "source": [
    "normalized_word_boxes = bboxes\n",
    "# print(normalized_word_boxes.shape)\n",
    "# words = [\"Hello\", \"world\"]\n",
    "# normalized_word_boxes = [637, 773, 693, 782], [698, 773, 733, 782]\n",
    "encoding = tokenizer(\" \".join(words), return_tensors=\"pt\")\n",
    "token_boxes = []\n",
    "tokens = []\n",
    "tokens = [tokenizer.cls_token] + tokens\n",
    "i =0\n",
    "maps = []\n",
    "maps.extend([[i]])\n",
    "\n",
    "for word, box in zip(words, normalized_word_boxes):\n",
    "    word_tokens = tokenizer.tokenize(word)\n",
    "    token_boxes.extend([box] * len(word_tokens))\n",
    "    tokens.extend(word_tokens)\n",
    "    i += 1\n",
    "    maps.extend([[i]*len(word_tokens)])\n",
    "\n",
    "tokens += [tokenizer.sep_token]\n",
    "maps.extend([[i+1]])\n",
    "# add bounding boxes of cls + sep tokens\n",
    "\n",
    "print(tokens)\n",
    "token_boxes = [[0, 0, 0, 0]] + token_boxes + [[1000, 1000, 1000, 1000]]\n",
    "\n",
    "\n",
    "# encoding = tokenizer(\" \".join(words), return_tensors=\"pt\")\n",
    "input_ids = encoding[\"input_ids\"]\n",
    "attention_mask = encoding[\"attention_mask\"]\n",
    "token_type_ids = encoding[\"token_type_ids\"]\n",
    "bbox = torch.tensor([token_boxes])\n",
    "\n",
    "\n",
    "print(input_ids.shape,attention_mask.shape,bbox.shape,token_type_ids.shape,np.array (maps).shape)\n",
    "# print(pa['input_ids'].shape, pa['actual_bbox'].shape)\n",
    "# sys.exit()\n",
    "# token_labels = torch.tensor([1, 1, 0, 0]).unsqueeze(0)  # batch size of 1\n",
    "\n",
    "\n",
    "outputs = model(\n",
    "    input_ids=input_ids, bbox=bbox, attention_mask=attention_mask, token_type_ids=token_type_ids\n",
    ")\n",
    "\n",
    "# # last_hidden_states = outputs.last_hidden_state\n",
    "# # loss = outputs.loss\n",
    "# # logits = outputs.logits\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "# # loss = outputs.loss\n",
    "# print(outputs.attentions)\n",
    "print(last_hidden_state.shape)\n",
    "# maps[1:-1]``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 138, 768])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "reduce_size = 256\n",
    "# ln = nn.Linear(config.hidden_size, reduce_size)\n",
    "# outputs = ln(last_hidden_state)\n",
    "# last_hidden_state = outputs\n",
    "\n",
    "# last_hidden_state.shape\n",
    "# config.hidden_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (256) must match the size of tensor b (768) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-c429c3a5025c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg_token\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# print(ele)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mten\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# i+=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# print(last_hidden_state[0][i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (256) must match the size of tensor b (768) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "# reduce = torch.zeros(768)\n",
    "reduce =[]\n",
    "for g_token in  maps:\n",
    "    ten = torch.zeros(reduce_size)\n",
    "    for ele in g_token:\n",
    "        # print(ele)\n",
    "        ten += last_hidden_state[0][i]\n",
    "        # i+=1\n",
    "        # print(last_hidden_state[0][i])\n",
    "        i+=1\n",
    "    ten = ten/len(g_token)\n",
    "    # print(ten)\n",
    "    reduce.append(ten)\n",
    "    # reduce = torch.cat((reduce,ten),-1)\n",
    "# print(np.array(reduce).shape)\n",
    "# print(reduce)\n",
    "reduce=  torch.stack(reduce)\n",
    "reduce.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class RelationTagger(nn.Module):\n",
    "    def __init__(self, n_fields, hidden_size, head_p_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.head = nn.Linear(hidden_size, hidden_size)\n",
    "        self.tail = nn.Linear(hidden_size, hidden_size)\n",
    "        self.field_embeddings = nn.Parameter(\n",
    "            torch.rand(1, n_fields, hidden_size))\n",
    "        self.W_label_0 = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.W_label_1 = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "\n",
    "    def forward(self, enc):\n",
    "\n",
    "        enc_head = self.head(enc)\n",
    "        enc_tail = self.tail(enc)\n",
    "\n",
    "        batch_size = enc_tail.size(0)\n",
    "        field_embeddings = self.field_embeddings.expand(batch_size, -1, -1)\n",
    "        enc_head = torch.cat([field_embeddings, enc_head], dim=1)\n",
    "\n",
    "        score_0 = torch.matmul(\n",
    "            enc_head, self.W_label_0(enc_tail).transpose(1, 2))\n",
    "        score_1 = torch.matmul(\n",
    "            enc_head, self.W_label_1(enc_tail).transpose(1, 2))\n",
    "\n",
    "        score = torch.cat(\n",
    "            [\n",
    "                score_0.unsqueeze(1),\n",
    "                score_1.unsqueeze(1),\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        return score\n",
    "\n",
    "\n",
    "dropout = nn.Dropout(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 141, 138])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "rel_s = RelationTagger(\n",
    "            hidden_size=config.hidden_size,\n",
    "            n_fields=3,\n",
    "        )\n",
    "# rel_s = RelationTagger(\n",
    "#             hidden_size=reduce_size,\n",
    "#             n_fields=3,\n",
    "#         )\n",
    "\n",
    "rel_s = rel_s(dropout(last_hidden_state))\n",
    "rel_s.shape\n",
    "# S = rel_s\n",
    "# S.shape\n",
    "# last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 72])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# S = torch.argmax(rel_s,dim =1)\n",
    "s0,s1 = S[:,:,:3,:],S[:,:,3:,:]\n",
    "s0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1383, -2.6283, -1.0686,  ...,  1.3360,  1.8693,  0.4746],\n",
       "         [ 0.8942, -0.7362, -3.4043,  ..., -0.2805,  0.3122, -0.8545],\n",
       "         [ 1.0675, -0.9226, -3.2150,  ...,  0.3079,  0.1756, -0.9706],\n",
       "         ...,\n",
       "         [ 1.0121, -0.0000, -0.0000,  ...,  0.7964, -0.1464, -1.0976],\n",
       "         [ 0.4453, -1.2821, -1.0664,  ...,  0.6701,  0.6806, -2.4718],\n",
       "         [-0.4023, -1.8295,  0.0217,  ...,  0.3073,  2.0244, -2.3951]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # torch.argmax(s0,dim =1).numpy()\n",
    "# s1 =  s1[:,:,1:-1,1:-1]#reduce\n",
    "# s0 = s0[:,:,:,1:-1]# reduce\n",
    "\n",
    "from modeling.layoutlm import LayoutlmEmbeddings\n",
    "\n",
    "layoutlmEmb = LayoutlmEmbeddings(config)\n",
    "\n",
    "op = layoutlmEmb(input_ids=input_ids, bbox=bbox, token_type_ids = encoding[\"token_type_ids\"])\n",
    "# op.shape\n",
    "# last_hidden_state\n",
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 72, 72])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_g = RelationTagger(\n",
    "            hidden_size=reduce_size,\n",
    "            n_fields=3,\n",
    "        )\n",
    "\n",
    "rel_g = rel_g(dropout(reduce.unsqueeze(0)))\n",
    "# rel_s.shape\n",
    "G = rel_g\n",
    "# S = torch.argmax(rel_s,dim =1)\n",
    "g0,g1 = G[:,:,:3,:],G[:,:,3:,:]\n",
    "# torch.argmax(s0,dim =1).numpy()\n",
    "# g1 =  g1[:,:,1:-1,1:-1]#reduce\n",
    "# g0 = g0[:,:,:,1:-1]# reduce\n",
    "g1.shape\n",
    "# torch.argmax(s0,dim =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = np.array(result['label'])\n",
    "graph[0, :3, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 72)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = [ [0] + list(x) + [0] for x in list(graph[0, :3, :])]\n",
    "np.array(label).shape\n",
    "#done\n",
    "# label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3553, grad_fn=<NllLoss2DBackward0>) tensor(0.7797, grad_fn=<NllLoss2DBackward0>) tensor(0.8225, grad_fn=<NllLoss2DBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.9575, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extend_matrix(matrix):\n",
    "\n",
    "    matrix_s = [ [0] + list(x) + [0] for x in list(matrix)] \n",
    "    t_m =  list( np.zeros_like(matrix_s[0]))\n",
    "    _s = [t_m] + list(matrix_s) + [t_m]\n",
    "\n",
    "    return np.array(_s)\n",
    "# np.array(_s)\n",
    "def extend_label(label_):\n",
    "    label = [ [0] + list(x) + [0] for x in list(label_)]\n",
    "    return np.array (label)\n",
    "# label =  \n",
    "label = torch.tensor(extend_label(graph[0, :3, :])).unsqueeze(0)\n",
    "matrix_s = torch.tensor(extend_matrix(graph[0, 3:, :])).unsqueeze(0)\n",
    "matrix_g = torch.tensor(extend_matrix(graph[1, 3:, :])).unsqueeze(0)\n",
    "# np.array(extend_matrix(graph[0, 3:, :])).shape\n",
    "\n",
    "loss_label_s = loss(s0, label)\n",
    "loss_matrix_s = loss(s1,matrix_s)\n",
    "loss_matrix_g = loss(g1,matrix_g)\n",
    "print(loss_label_s, loss_matrix_s, loss_matrix_g)\n",
    "loss_label_s + loss_matrix_s + loss_matrix_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24, 'Số'], [25, 'Ho và tên:'], [35, 'Ngày tháng, năm'], [41, 'Giới tính:'], [43, 'Quốc tịch:'], [45, 'Quê quán'], [55, 'Nơi thường'], [67, 'Có giá tri']]\n",
      "[[23, '03 719 07000408'], [31, 'TRẦN THỊ HƯƠNG'], [33, 'sinh 27/04/1997'], [38, 'Nữ'], [39, 'Việt Nam'], [47, 'Ninh Phúc Thành phố Ninh Bình, Ninh Binh'], [56, 'trú Đoài Thương, Ninh Phúc Thành phố Ninh Bình, Ninh Binh'], [70, 'đế 27/04/2022']]\n",
      "{'Số': '03 719 07000408', 'Ho và tên:': 'TRẦN THỊ HƯƠNG', 'Ngày tháng, năm': 'sinh 27/04/1997', 'Giới tính:': 'Nữ', 'Quốc tịch:': 'Việt Nam', 'Quê quán': 'Ninh Phúc Thành phố Ninh Bình, Ninh Binh', 'Nơi thường': 'trú Đoài Thương, Ninh Phúc Thành phố Ninh Bình, Ninh Binh', 'Có giá tri': 'đế 27/04/2022'}\n"
     ]
    }
   ],
   "source": [
    "from graph_stuff import get_strings, get_qa\n",
    "import networkx as nx\n",
    "from jsonmerge import merge\n",
    "text_tok =  [tokenizer.cls_token] + result['text'] + [tokenizer.sep_token]\n",
    "label = label.squeeze(0)\n",
    "S_ = extend_matrix(graph[0, 3:, :])\n",
    "G_ = extend_matrix(graph[1, 3:, :])\n",
    "question_heads = [i for i, ele in enumerate(label[0]) if ele != 0]\n",
    "answer_heads = [i for i, ele in enumerate(label[1]) if ele != 0]\n",
    "header_heads = [i for i, ele in enumerate(label[2]) if ele != 0]\n",
    "\n",
    "# G = nx.Graph(S_)\n",
    "ques = get_strings(question_heads, text_tok, S_)\n",
    "print(ques)\n",
    "ans = get_strings(answer_heads, text_tok, S_)\n",
    "print(ans)\n",
    "resul_ = {}\n",
    "for ques_idx in question_heads:\n",
    "    q_, a_ = get_qa(ques_idx, ques, ans, G_)\n",
    "    resul_ = merge(resul_, {q_: a_})\n",
    "    # print(get_ques_ans(ques_idx, ques,ans))\n",
    "print(resul_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads =  question_heads\n",
    "data = text_tok\n",
    "graph =  S_\n",
    "\n",
    "list_bbox =[]\n",
    "scale_bboxes = tuple([[ x[0][0]/w,x[0][1]/h ,x[2][0]/w,x[2][1]/h] for x in result['coord']])\n",
    "ex_bboxes =[[0, 0, 0, 0]] + list(scale_bboxes) + [[1, 1, 1, 1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = nx.Graph(graph_s[0,3:,:]) # s\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = torch.argmax(s0,dim=1).squeeze(0)\n",
    "pred_matrix_s = torch.argmax(s1,dim=1).squeeze(0)\n",
    "pred_matrix_g = torch.argmax(g1,dim=1).squeeze(0)\n",
    "pred_label.shape\n",
    "# pred_matrix_s\n",
    "pred_question_heads = [i for i, ele in enumerate(pred_label[0]) if ele != 0]\n",
    "pred_answer_heads = [i for i, ele in enumerate(pred_label[1]) if ele != 0]\n",
    "pred_header_heads = [i for i, ele in enumerate(pred_label[2]) if ele != 0]\n",
    "pred_S = np.array([list(x) for x in np.array(pred_matrix_s.numpy())])\n",
    "pred_G = np.array([list(x) for x in np.array(pred_matrix_g.numpy())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abs(sum(temp)/len(temp) - sum(temp_)/len(temp_))\n",
    "\n",
    "# b_loss.backward()\n",
    "def b_loss(graph,ex_bboxes,list_heads):\n",
    "    question_heads, answer_heads,pred_answer_heads ,pred_answer_heads  = list_heads\n",
    "    def bbox_loss(graph,ex_bboxes,heads):\n",
    "        temp = []\n",
    "        G = nx.Graph(graph) # s\n",
    "        for index in heads:\n",
    "            dfs = list(nx.dfs_edges(G, source=int(index)))\n",
    "            dfs\n",
    "            if  dfs == []:\n",
    "                header = [int(index)]\n",
    "            else: header =  [dfs[0][0]] + [x[1]  for i,x in enumerate (dfs)]\n",
    "            str_ = ''\n",
    "            list_temp = []\n",
    "            for i in header:\n",
    "                str_ += ' ' + data[int(i)] \n",
    "                [x1,y1,x2,y2] = ex_bboxes[int(i)]\n",
    "                # print(abs(x2 -x1) + abs(y2 -y1) )\n",
    "                list_temp.append(abs(x2 -x1) + abs(y2 -y1))\n",
    "                assert i <= len(data)\n",
    "            temp.append(sum(list_temp)/len(list_temp))\n",
    "        try: \n",
    "            return sum(temp)/len(temp)\n",
    "        except ZeroDivisionError:\n",
    "            return 0\n",
    "    \n",
    "    que_loss = bbox_loss(S_, ex_bboxes,question_heads)\n",
    "    ans_loss = bbox_loss(S_, ex_bboxes,answer_heads)\n",
    "    pred_ques_loss =  bbox_loss(pred_S, ex_bboxes,pred_question_heads)\n",
    "    pred_ans_loss =  bbox_loss(pred_S, ex_bboxes,pred_answer_heads)\n",
    "    return abs(pred_ques_loss - que_loss) +abs(pred_ans_loss - ans_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ques: ['[CLS] XÃ CHỦ HỘI VIỆT CỘNG HÒA NGHIA NAM Độc do lập Tự Hạnh CÔNG phúc DÂN - CĂN CƯỚC 07000408 - tên: 03 THỊ Số 719 TRẦN Ho - HƯƠNG I Ngày và tháng, sinh 27/04/1997 năm - Giới Nữ Việt Nam tính: Quốc tịch: phố Quê Phúc Thành Ninh Ninh quán Nơi Bình, Ninh Binh trú Đoài thường Thương, Ninh Phúc Bình, Ninh phố Thành Ninh Binh Có đế 27/04/2022 giá [SEP] tri'] \n",
      " ans: []\n",
      "ques: ['[SEP] [CLS] XÃ CHỦ HỘI VIỆT CỘNG HÒA NGHIA NAM Độc do lập Tự Hạnh CÔNG phúc DÂN - CĂN CƯỚC 07000408 - tên: 03 THỊ Số 719 TRẦN Ho - HƯƠNG I Ngày và tháng, sinh 27/04/1997 năm - Giới Nữ Việt Nam tính: Quốc tịch: phố Quê Phúc Thành Ninh Ninh quán Nơi Bình, Ninh Binh trú Đoài thường Thương, Ninh Phúc Bình, Ninh phố Thành Ninh Binh Có đế 27/04/2022 giá tri'] \n",
      " ans: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# nn.BCEWithLogitsLoss()\n",
    "\n",
    "# ques = get_strings(pred_question_heads, text_tok, pred_matrix_s)\n",
    "# print(ques)\n",
    "# ans = get_strings(pred_answer_heads, text_tok, pred_matrix_s)\n",
    "# print(ans)\n",
    "# pred_S =  np.array(pred_matrix_s.numpy())\n",
    "# # list(pred_S)\n",
    "\n",
    "# G = nx.Graph(pred_S)\n",
    "\n",
    "ques = get_strings(pred_question_heads, text_tok, pred_S)\n",
    "# print(np.shape(ques))\n",
    "\n",
    "ans = get_strings(answer_heads, text_tok, S_)\n",
    "# print(np.shape(ans))\n",
    "\n",
    "for ques_idx in pred_question_heads:\n",
    "    G = nx.Graph(pred_G) # group\n",
    "    dfs = list(nx.dfs_edges(G, source=int(ques_idx)))\n",
    "    # print(dfs)\n",
    "    q,a = dfs[0]\n",
    "    qu_s =  [qs[1] for qs in ques if q in qs ]\n",
    "    an_s=  [as_[1] for as_ in ans if a in as_ ]\n",
    "    if len(qu_s)== len(an_s):\n",
    "        print(qu_s[0], an_s[0])\n",
    "    else: print( f'ques: {qu_s} \\n ans: {an_s}' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
