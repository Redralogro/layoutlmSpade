{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/layoutlm-base-uncased were not used when initializing LayoutLMModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing LayoutLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LayoutLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, BatchEncoding, BertModel,LayoutLMModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/layoutlm-base-uncased\")\n",
    "model = LayoutLMModel.from_pretrained(\"microsoft/layoutlm-base-uncased\")\n",
    "config = AutoConfig.from_pretrained(\"microsoft/layoutlm-base-uncased\")\n",
    "config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# result = json.load(open('./data/raw/truong_raw.jsonl'))\n",
    "# result['boxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "result = json.load(open('./data/processed/train/huy.jsonl'))\n",
    "result = json.load(open('data/processed/train/trinh.jsonl'))\n",
    "result = json.load(open('data/processed/train/kha.jsonl'))\n",
    "result = json.load(open('data/processed/train/linh.jsonl'))\n",
    "# result = json.load(open('data/processed/trinh.jsonl'))\n",
    "# result = json.load(open('data/processed/trinh.jsonl'))\n",
    "words = result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_input(words, coord, size_):\n",
    "        w,h = size_\n",
    "        bboxes = tuple([[ int(x[0][0]*1000/w),int(x[0][1]*1000/h) ,int(x[2][0]*1000/w),int(x[2][1]*1000/h)] for x in coord])\n",
    "        normalized_word_boxes = bboxes\n",
    "        encoding = tokenizer(' '.join(words), return_tensors=\"pt\")\n",
    "        token_boxes = []\n",
    "        tokens = []\n",
    "        tokens = [tokenizer.cls_token] + tokens\n",
    "        i =0\n",
    "        maps = []\n",
    "        maps.extend([[i]])\n",
    "        for word, box in zip(words, normalized_word_boxes):\n",
    "            word_tokens = tokenizer.tokenize(word)\n",
    "            token_boxes.extend([box] * len(word_tokens))\n",
    "            tokens.extend(word_tokens)\n",
    "            i += 1\n",
    "            maps.extend([[i]*len(word_tokens)])\n",
    "\n",
    "        tokens += [tokenizer.sep_token]\n",
    "        maps.extend([[i+1]])\n",
    "\n",
    "        input_ids = encoding[\"input_ids\"]\n",
    "        attention_mask = encoding[\"attention_mask\"]\n",
    "        token_type_ids = encoding[\"token_type_ids\"]\n",
    "        bbox = torch.tensor([token_boxes])\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask,'token_type_ids':token_type_ids,'bbox':bbox , 'maps': maps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (148) must match the size of tensor b (146) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-929928401b5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# int(2.3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coord'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m outputs = model(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/layoutlm/modeling_layoutlm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, bbox, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0mbbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/layoutlm/modeling_layoutlm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, bbox, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         embeddings = (\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mwords_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0mleft_position_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (148) must match the size of tensor b (146) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "w, h = Image.open(result['data_id']).size\n",
    "w,h\n",
    "# int(2.3)\n",
    "input_ = handle_input(words,result['coord'],(w,h))\n",
    "outputs = model(\n",
    "    input_ids=input_['input_ids'], bbox=input_['bbox'], attention_mask=input_['attention_mask'], token_type_ids=input_['token_type_ids']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([436, 33, 474, 81],\n",
       " [448, 81, 481, 129],\n",
       " [474, 33, 523, 81],\n",
       " [492, 81, 525, 129],\n",
       " [525, 33, 582, 85],\n",
       " [582, 33, 661, 81],\n",
       " [293, 37, 373, 88],\n",
       " [373, 37, 431, 85],\n",
       " [661, 37, 723, 88],\n",
       " [725, 37, 784, 85],\n",
       " [525, 85, 565, 118],\n",
       " [403, 88, 448, 125],\n",
       " [370, 125, 476, 162],\n",
       " [568, 88, 622, 122],\n",
       " [624, 88, 673, 129],\n",
       " [72, 133, 89, 159],\n",
       " [476, 129, 579, 162],\n",
       " [373, 162, 502, 196],\n",
       " [516, 162, 593, 196],\n",
       " [584, 133, 615, 162],\n",
       " [615, 129, 661, 162],\n",
       " [666, 129, 713, 162],\n",
       " [612, 162, 706, 196],\n",
       " [295, 211, 394, 296],\n",
       " [690, 211, 791, 296],\n",
       " [403, 214, 537, 292],\n",
       " [551, 222, 678, 288],\n",
       " [852, 240, 946, 270],\n",
       " [462, 322, 518, 370],\n",
       " [295, 325, 373, 370],\n",
       " [375, 325, 460, 374],\n",
       " [401, 396, 744, 466],\n",
       " [295, 414, 330, 462],\n",
       " [347, 418, 394, 462],\n",
       " [368, 485, 408, 533],\n",
       " [422, 485, 467, 540],\n",
       " [467, 485, 539, 540],\n",
       " [417, 540, 542, 596],\n",
       " [485, 596, 514, 651],\n",
       " [514, 596, 570, 651],\n",
       " [298, 488, 330, 529],\n",
       " [335, 488, 366, 529],\n",
       " [549, 533, 636, 596],\n",
       " [575, 596, 748, 659],\n",
       " [291, 537, 413, 603],\n",
       " [107, 577, 124, 600],\n",
       " [293, 607, 361, 662],\n",
       " [363, 611, 413, 651],\n",
       " [431, 607, 485, 655],\n",
       " [685, 670, 701, 725],\n",
       " [572, 670, 638, 725],\n",
       " [295, 674, 349, 725],\n",
       " [638, 674, 685, 729],\n",
       " [701, 674, 821, 729],\n",
       " [788, 733, 861, 792],\n",
       " [821, 674, 882, 733],\n",
       " [352, 681, 399, 725],\n",
       " [413, 681, 462, 725],\n",
       " [889, 677, 957, 729],\n",
       " [464, 681, 535, 733],\n",
       " [584, 733, 650, 796],\n",
       " [650, 733, 730, 800],\n",
       " [734, 733, 786, 796],\n",
       " [427, 748, 490, 796],\n",
       " [490, 748, 518, 792],\n",
       " [518, 744, 584, 807],\n",
       " [295, 751, 347, 800],\n",
       " [291, 800, 333, 848],\n",
       " [349, 748, 413, 800],\n",
       " [338, 800, 394, 851],\n",
       " [474, 851, 488, 903],\n",
       " [293, 851, 340, 903],\n",
       " [342, 851, 436, 903],\n",
       " [427, 903, 476, 955],\n",
       " [697, 844, 739, 907],\n",
       " [821, 844, 892, 900],\n",
       " [553, 851, 584, 900],\n",
       " [741, 844, 816, 911],\n",
       " [892, 844, 960, 907],\n",
       " [436, 851, 474, 900],\n",
       " [488, 851, 553, 903],\n",
       " [584, 851, 694, 900],\n",
       " [39, 925, 157, 985],\n",
       " [11, 866, 86, 925],\n",
       " [86, 881, 105, 929],\n",
       " [105, 877, 150, 922],\n",
       " [286, 903, 335, 962],\n",
       " [476, 903, 535, 966],\n",
       " [340, 907, 420, 970],\n",
       " [157, 955, 173, 985])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes = tuple([[ int(x[0][0]*1000/w),int(x[0][1]*1000/h) ,int(x[2][0]*1000/w),int(x[2][1]*1000/h)] for x in result['coord']])\n",
    "# bboxes = tuple(bboxes)\n",
    "bboxes\n",
    "\n",
    "# text label data_id coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1060,  2050,  5001,  7570,  2072, 10722, 14684, 12835, 12995,\n",
       "          26478,  7570,  2050, 19710, 15125,  2079,  1102, 10085,  6102,  7658,\n",
       "           2232,  6887, 14194,  1056,  2002,  2226, 16577, 16577,  4013, 19053,\n",
       "           2389,  5709, 19710, 12436,  5112, 15125,  2064,  4907, 12731, 10085,\n",
       "          26478,  1011,  4003,  6926, 12631,  2078, 25604, 28332, 24096, 21057,\n",
       "          25746,  2061,  6583,  2226,  2702, 11865,  4886,  2171,  4291,  1997,\n",
       "           4182,  7570, 12436, 11409,  2232,  5890,  1013,  6185,  1013,  2456,\n",
       "          13012, 25311,  5003, 12835,  4710,  8254,  2232, 23755,  2080,  1018,\n",
       "          22035,  2278, 21025, 10448, 14841,  2818, 10662, 11409,  2232, 19710,\n",
       "           9543,  2232,  2712, 15125, 15125,  4682,  2078,  6097,  1010,  2033,\n",
       "           2173,  1997,  2006,  2290, 18699, 22035,  5292, 24110,  2053,  2072,\n",
       "           1011,  2053,  2072, 16215, 19098,  3070,  5292,  1060,  2050,  4682,\n",
       "           2078,  1997,  6097,  1010,  6097, 19817,  2226,  2173, 20996,  5332,\n",
       "          17679,  5890,  1013,  6185,  1013,  3263,  2522,  6643,  1058, 12411,\n",
       "           2033,  2053,  2072, 11409,  2232,  1010,  1019,   102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0]]),\n",
       " 'bbox': tensor([[[   0,    0,    0,    0],\n",
       "          [ 436,   33,  474,   81],\n",
       "          [ 436,   33,  474,   81],\n",
       "          [ 448,   81,  481,  129],\n",
       "          [ 474,   33,  523,   81],\n",
       "          [ 474,   33,  523,   81],\n",
       "          [ 492,   81,  525,  129],\n",
       "          [ 525,   33,  582,   85],\n",
       "          [ 582,   33,  661,   81],\n",
       "          [ 582,   33,  661,   81],\n",
       "          [ 293,   37,  373,   88],\n",
       "          [ 373,   37,  431,   85],\n",
       "          [ 373,   37,  431,   85],\n",
       "          [ 661,   37,  723,   88],\n",
       "          [ 725,   37,  784,   85],\n",
       "          [ 525,   85,  565,  118],\n",
       "          [ 403,   88,  448,  125],\n",
       "          [ 403,   88,  448,  125],\n",
       "          [ 370,  125,  476,  162],\n",
       "          [ 568,   88,  622,  122],\n",
       "          [ 568,   88,  622,  122],\n",
       "          [ 624,   88,  673,  129],\n",
       "          [ 624,   88,  673,  129],\n",
       "          [  72,  133,   89,  159],\n",
       "          [ 476,  129,  579,  162],\n",
       "          [ 476,  129,  579,  162],\n",
       "          [ 373,  162,  502,  196],\n",
       "          [ 373,  162,  502,  196],\n",
       "          [ 516,  162,  593,  196],\n",
       "          [ 516,  162,  593,  196],\n",
       "          [ 516,  162,  593,  196],\n",
       "          [ 584,  133,  615,  162],\n",
       "          [ 615,  129,  661,  162],\n",
       "          [ 666,  129,  713,  162],\n",
       "          [ 612,  162,  706,  196],\n",
       "          [ 612,  162,  706,  196],\n",
       "          [ 295,  211,  394,  296],\n",
       "          [ 690,  211,  791,  296],\n",
       "          [ 403,  214,  537,  292],\n",
       "          [ 403,  214,  537,  292],\n",
       "          [ 551,  222,  678,  288],\n",
       "          [ 852,  240,  946,  270],\n",
       "          [ 462,  322,  518,  370],\n",
       "          [ 295,  325,  373,  370],\n",
       "          [ 375,  325,  460,  374],\n",
       "          [ 375,  325,  460,  374],\n",
       "          [ 401,  396,  744,  466],\n",
       "          [ 401,  396,  744,  466],\n",
       "          [ 401,  396,  744,  466],\n",
       "          [ 401,  396,  744,  466],\n",
       "          [ 401,  396,  744,  466],\n",
       "          [ 295,  414,  330,  462],\n",
       "          [ 347,  418,  394,  462],\n",
       "          [ 347,  418,  394,  462],\n",
       "          [ 368,  485,  408,  533],\n",
       "          [ 422,  485,  467,  540],\n",
       "          [ 422,  485,  467,  540],\n",
       "          [ 467,  485,  539,  540],\n",
       "          [ 417,  540,  542,  596],\n",
       "          [ 485,  596,  514,  651],\n",
       "          [ 514,  596,  570,  651],\n",
       "          [ 298,  488,  330,  529],\n",
       "          [ 335,  488,  366,  529],\n",
       "          [ 549,  533,  636,  596],\n",
       "          [ 549,  533,  636,  596],\n",
       "          [ 575,  596,  748,  659],\n",
       "          [ 575,  596,  748,  659],\n",
       "          [ 575,  596,  748,  659],\n",
       "          [ 575,  596,  748,  659],\n",
       "          [ 575,  596,  748,  659],\n",
       "          [ 291,  537,  413,  603],\n",
       "          [ 291,  537,  413,  603],\n",
       "          [ 107,  577,  124,  600],\n",
       "          [ 293,  607,  361,  662],\n",
       "          [ 293,  607,  361,  662],\n",
       "          [ 363,  611,  413,  651],\n",
       "          [ 363,  611,  413,  651],\n",
       "          [ 431,  607,  485,  655],\n",
       "          [ 431,  607,  485,  655],\n",
       "          [ 685,  670,  701,  725],\n",
       "          [ 572,  670,  638,  725],\n",
       "          [ 572,  670,  638,  725],\n",
       "          [ 295,  674,  349,  725],\n",
       "          [ 295,  674,  349,  725],\n",
       "          [ 638,  674,  685,  729],\n",
       "          [ 638,  674,  685,  729],\n",
       "          [ 701,  674,  821,  729],\n",
       "          [ 788,  733,  861,  792],\n",
       "          [ 788,  733,  861,  792],\n",
       "          [ 821,  674,  882,  733],\n",
       "          [ 352,  681,  399,  725],\n",
       "          [ 352,  681,  399,  725],\n",
       "          [ 413,  681,  462,  725],\n",
       "          [ 889,  677,  957,  729],\n",
       "          [ 464,  681,  535,  733],\n",
       "          [ 584,  733,  650,  796],\n",
       "          [ 584,  733,  650,  796],\n",
       "          [ 650,  733,  730,  800],\n",
       "          [ 650,  733,  730,  800],\n",
       "          [ 734,  733,  786,  796],\n",
       "          [ 427,  748,  490,  796],\n",
       "          [ 490,  748,  518,  792],\n",
       "          [ 518,  744,  584,  807],\n",
       "          [ 518,  744,  584,  807],\n",
       "          [ 518,  744,  584,  807],\n",
       "          [ 295,  751,  347,  800],\n",
       "          [ 291,  800,  333,  848],\n",
       "          [ 349,  748,  413,  800],\n",
       "          [ 338,  800,  394,  851],\n",
       "          [ 338,  800,  394,  851],\n",
       "          [ 474,  851,  488,  903],\n",
       "          [ 293,  851,  340,  903],\n",
       "          [ 293,  851,  340,  903],\n",
       "          [ 342,  851,  436,  903],\n",
       "          [ 342,  851,  436,  903],\n",
       "          [ 342,  851,  436,  903],\n",
       "          [ 427,  903,  476,  955],\n",
       "          [ 697,  844,  739,  907],\n",
       "          [ 697,  844,  739,  907],\n",
       "          [ 821,  844,  892,  900],\n",
       "          [ 821,  844,  892,  900],\n",
       "          [ 553,  851,  584,  900],\n",
       "          [ 741,  844,  816,  911],\n",
       "          [ 741,  844,  816,  911],\n",
       "          [ 892,  844,  960,  907],\n",
       "          [ 436,  851,  474,  900],\n",
       "          [ 436,  851,  474,  900],\n",
       "          [ 488,  851,  553,  903],\n",
       "          [ 584,  851,  694,  900],\n",
       "          [ 584,  851,  694,  900],\n",
       "          [ 584,  851,  694,  900],\n",
       "          [  39,  925,  157,  985],\n",
       "          [  39,  925,  157,  985],\n",
       "          [  39,  925,  157,  985],\n",
       "          [  39,  925,  157,  985],\n",
       "          [  39,  925,  157,  985],\n",
       "          [  11,  866,   86,  925],\n",
       "          [  11,  866,   86,  925],\n",
       "          [  86,  881,  105,  929],\n",
       "          [ 105,  877,  150,  922],\n",
       "          [ 286,  903,  335,  962],\n",
       "          [ 476,  903,  535,  966],\n",
       "          [ 476,  903,  535,  966],\n",
       "          [ 340,  907,  420,  970],\n",
       "          [ 340,  907,  420,  970],\n",
       "          [ 340,  907,  420,  970],\n",
       "          [ 157,  955,  173,  985],\n",
       "          [1000, 1000, 1000, 1000]]]),\n",
       " 'maps': [[0],\n",
       "  [1, 1],\n",
       "  [2],\n",
       "  [3, 3],\n",
       "  [4],\n",
       "  [5],\n",
       "  [6, 6],\n",
       "  [7],\n",
       "  [8, 8],\n",
       "  [9],\n",
       "  [10],\n",
       "  [11],\n",
       "  [12, 12],\n",
       "  [13],\n",
       "  [14, 14],\n",
       "  [15, 15],\n",
       "  [16],\n",
       "  [17, 17],\n",
       "  [18, 18],\n",
       "  [19, 19, 19],\n",
       "  [20],\n",
       "  [21],\n",
       "  [22],\n",
       "  [23, 23],\n",
       "  [24],\n",
       "  [25],\n",
       "  [26, 26],\n",
       "  [27],\n",
       "  [28],\n",
       "  [29],\n",
       "  [30],\n",
       "  [31, 31],\n",
       "  [32, 32, 32, 32, 32],\n",
       "  [33],\n",
       "  [34, 34],\n",
       "  [35],\n",
       "  [36, 36],\n",
       "  [37],\n",
       "  [38],\n",
       "  [39],\n",
       "  [40],\n",
       "  [41],\n",
       "  [42],\n",
       "  [43, 43],\n",
       "  [44, 44, 44, 44, 44],\n",
       "  [45, 45],\n",
       "  [46],\n",
       "  [47, 47],\n",
       "  [48, 48],\n",
       "  [49, 49],\n",
       "  [50],\n",
       "  [51, 51],\n",
       "  [52, 52],\n",
       "  [53, 53],\n",
       "  [54],\n",
       "  [55, 55],\n",
       "  [56],\n",
       "  [57, 57],\n",
       "  [58],\n",
       "  [59],\n",
       "  [60],\n",
       "  [61, 61],\n",
       "  [62, 62],\n",
       "  [63],\n",
       "  [64],\n",
       "  [65],\n",
       "  [66, 66, 66],\n",
       "  [67],\n",
       "  [68],\n",
       "  [69],\n",
       "  [70, 70],\n",
       "  [71],\n",
       "  [72, 72],\n",
       "  [73, 73, 73],\n",
       "  [74],\n",
       "  [75, 75],\n",
       "  [76, 76],\n",
       "  [77],\n",
       "  [78, 78],\n",
       "  [79],\n",
       "  [80, 80],\n",
       "  [81],\n",
       "  [82, 82, 82],\n",
       "  [83, 83, 83, 83, 83],\n",
       "  [84, 84],\n",
       "  [85],\n",
       "  [86],\n",
       "  [87],\n",
       "  [88, 88],\n",
       "  [89, 89, 89],\n",
       "  [90],\n",
       "  [91]]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def handel(word, coord, size):\n",
    "    w,h = size\n",
    "    normalized_word_boxes = tuple([[ int(x[0][0]*1000/w),int(x[0][1]*1000/h) ,int(x[2][0]*1000/w),int(x[2][1]*1000/h)] for x in coord])\n",
    "    encoding = tokenizer(\" \".join(words), return_tensors=\"pt\")\n",
    "    token_boxes = []\n",
    "    tokens = []\n",
    "    tokens = [tokenizer.cls_token] + tokens\n",
    "    i =0\n",
    "    maps = []\n",
    "    maps.extend([[i]])\n",
    "\n",
    "    for word, box in zip(words, normalized_word_boxes):\n",
    "        word_tokens = tokenizer.tokenize(word)\n",
    "        token_boxes.extend([box] * len(word_tokens))\n",
    "        tokens.extend(word_tokens)\n",
    "        i += 1\n",
    "        maps.extend([[i]*len(word_tokens)])\n",
    "\n",
    "    tokens += [tokenizer.sep_token]\n",
    "    maps.extend([[i+1]])\n",
    "\n",
    "    token_boxes = [[0, 0, 0, 0]] + token_boxes + [[1000, 1000, 1000, 1000]]\n",
    "\n",
    "    input_ids = encoding[\"input_ids\"]\n",
    "    attention_mask = encoding[\"attention_mask\"]\n",
    "    token_type_ids = encoding[\"token_type_ids\"]\n",
    "    bbox = torch.tensor([token_boxes])\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask,'token_type_ids':token_type_ids,'bbox':bbox , 'maps': maps}\n",
    "\n",
    "handel(words,result['coord'],(w,h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [1, 1], [2], [3, 3], [4], [5], [6, 6], [7], [8, 8], [9], [10], [11], [12, 12], [13], [14, 14], [15, 15], [16], [17, 17], [18, 18], [19, 19, 19], [20], [21], [22], [23, 23], [24], [25], [26, 26], [27], [28], [29], [30], [31, 31], [32, 32, 32, 32, 32], [33], [34, 34], [35], [36, 36], [37], [38], [39], [40], [41], [42], [43, 43], [44, 44, 44, 44, 44], [45, 45], [46], [47, 47], [48, 48], [49, 49], [50], [51, 51], [52, 52], [53, 53], [54], [55, 55], [56], [57, 57], [58], [59], [60], [61, 61], [62, 62], [63], [64], [65], [66, 66, 66], [67], [68], [69], [70, 70], [71], [72, 72], [73, 73, 73], [74], [75, 75], [76, 76], [77], [78, 78], [79], [80, 80], [81], [82, 82, 82], [83, 83, 83, 83, 83], [84, 84], [85], [86], [87], [88, 88], [89, 89, 89], [90], [91]]\n",
      "['[CLS]', 'x', '##a', 'lap', 'ho', '##i', 'tu', 'chu', 'ng', '##hia', 'cong', 'ho', '##a', 'viet', 'nam', 'do', 'đ', '##oc', 'socialist', 'han', '##h', 'ph', '##uc', 't', 'he', '##u', 'nguyen', 'nguyen', 'pro', '##cic', '##al', '05', 'viet', 'va', 'hung', 'nam', 'can', 'dan', 'cu', '##oc', 'cong', '-', 'card', 'citizen', 'kin', '##n', '001', '##200', '##01', '##90', '##52', 'so', 'na', '##u', 'ten', 'fu', '##ai', 'name', 'hong', 'of', 'birth', 'ho', 'va', 'lin', '##h', '01', '/', '02', '/', '2000', 'tri', '##nh', 'ma', 'ng', '##ay', 'sin', '##h', 'dat', '##o', '4', 'quo', '##c', 'gi', '##oi', 'ti', '##ch', 'nationality', 'lin', '##h', 'viet', 'tin', '##h', 'sea', 'nam', 'nam', 'lie', '##n', 'mac', ',', 'me', 'place', 'of', 'on', '##g', 'nh', 'quo', 'ha', 'quan', 'no', '##i', '-', 'no', '##i', 'th', '##uo', '##ng', 'ha', 'x', '##a', 'lie', '##n', 'of', 'mac', ',', 'mac', 'tr', '##u', 'place', 'ro', '##si', '##dong', '01', '/', '02', '/', '200', 'co', 'pa', 'v', 'sen', 'me', 'no', '##i', 'lin', '##h', ',', '5', '[SEP]']\n",
      "(148, 4)\n",
      "torch.Size([1, 148, 4])\n",
      "torch.Size([1, 148, 768])\n"
     ]
    }
   ],
   "source": [
    "normalized_word_boxes = bboxes\n",
    "# print(normalized_word_boxes.shape)\n",
    "# words = [\"Hello\", \"world\"]\n",
    "# normalized_word_boxes = [637, 773, 693, 782], [698, 773, 733, 782]\n",
    "encoding = tokenizer(\" \".join(words), return_tensors=\"pt\")\n",
    "token_boxes = []\n",
    "tokens = []\n",
    "tokens = [tokenizer.cls_token] + tokens\n",
    "i =0\n",
    "maps = []\n",
    "maps.extend([[i]])\n",
    "\n",
    "for word, box in zip(words, normalized_word_boxes):\n",
    "    word_tokens = tokenizer.tokenize(word)\n",
    "    token_boxes.extend([box] * len(word_tokens))\n",
    "    tokens.extend(word_tokens)\n",
    "    i += 1\n",
    "    maps.extend([[i]*len(word_tokens)])\n",
    "\n",
    "tokens += [tokenizer.sep_token]\n",
    "maps.extend([[i+1]])\n",
    "# add bounding boxes of cls + sep tokens\n",
    "\n",
    "print(tokens)\n",
    "token_boxes = [[0, 0, 0, 0]] + token_boxes + [[1000, 1000, 1000, 1000]]\n",
    "\n",
    "\n",
    "# encoding = tokenizer(\" \".join(words), return_tensors=\"pt\")\n",
    "input_ids = encoding[\"input_ids\"]\n",
    "attention_mask = encoding[\"attention_mask\"]\n",
    "token_type_ids = encoding[\"token_type_ids\"]\n",
    "bbox = torch.tensor([token_boxes])\n",
    "\n",
    "\n",
    "print(input_ids.shape,attention_mask.shape,bbox.shape,token_type_ids.shape)\n",
    "# print(pa['input_ids'].shape, pa['actual_bbox'].shape)\n",
    "# sys.exit()\n",
    "# token_labels = torch.tensor([1, 1, 0, 0]).unsqueeze(0)  # batch size of 1\n",
    "\n",
    "# outputs = model(\n",
    "#     input_ids=pa['input_ids'],\n",
    "#     bbox=tuple(result['boxes']),\n",
    "#     attention_mask=pa['attention_mask'],\n",
    "#     token_type_ids=pa['token_type_ids'],\n",
    "# )\n",
    "outputs = model(\n",
    "    input_ids=input_ids, bbox=bbox, attention_mask=attention_mask, token_type_ids=token_type_ids\n",
    ")\n",
    "\n",
    "# # last_hidden_states = outputs.last_hidden_state\n",
    "# # loss = outputs.loss\n",
    "# # logits = outputs.logits\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "# # loss = outputs.loss\n",
    "# print(outputs.attentions)\n",
    "print(last_hidden_state.shape)\n",
    "# maps[1:-1]``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "reduce_size = 256\n",
    "ln = nn.Linear(config.hidden_size, reduce_size)\n",
    "outputs = ln(last_hidden_state)\n",
    "last_hidden_state = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([92, 256])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "# reduce = torch.zeros(768)\n",
    "reduce =[]\n",
    "for g_token in  maps:\n",
    "    ten = torch.zeros(reduce_size)\n",
    "    for ele in g_token:\n",
    "        # print(ele)\n",
    "        ten += last_hidden_state[0][i]\n",
    "        # i+=1\n",
    "        # print(last_hidden_state[0][i])\n",
    "        i+=1\n",
    "    ten = ten/len(g_token)\n",
    "    # print(ten)\n",
    "    reduce.append(ten)\n",
    "    # reduce = torch.cat((reduce,ten),-1)\n",
    "# print(np.array(reduce).shape)\n",
    "# print(reduce)\n",
    "reduce=  torch.stack(reduce)\n",
    "reduce.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class RelationTagger(nn.Module):\n",
    "    def __init__(self, n_fields, hidden_size, head_p_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.head = nn.Linear(hidden_size, hidden_size)\n",
    "        self.tail = nn.Linear(hidden_size, hidden_size)\n",
    "        self.field_embeddings = nn.Parameter(\n",
    "            torch.rand(1, n_fields, hidden_size))\n",
    "        self.W_label_0 = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.W_label_1 = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "\n",
    "    def forward(self, enc):\n",
    "\n",
    "        enc_head = self.head(enc)\n",
    "        enc_tail = self.tail(enc)\n",
    "\n",
    "        batch_size = enc_tail.size(0)\n",
    "        field_embeddings = self.field_embeddings.expand(batch_size, -1, -1)\n",
    "        enc_head = torch.cat([field_embeddings, enc_head], dim=1)\n",
    "\n",
    "        score_0 = torch.matmul(\n",
    "            enc_head, self.W_label_0(enc_tail).transpose(1, 2))\n",
    "        score_1 = torch.matmul(\n",
    "            enc_head, self.W_label_1(enc_tail).transpose(1, 2))\n",
    "\n",
    "        score = torch.cat(\n",
    "            [\n",
    "                score_0.unsqueeze(1),\n",
    "                score_1.unsqueeze(1),\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        return score\n",
    "\n",
    "\n",
    "dropout = nn.Dropout(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "rel_s = RelationTagger(\n",
    "            hidden_size=reduce_size,\n",
    "            n_fields=3,\n",
    "        )\n",
    "\n",
    "rel_s = rel_s(dropout(reduce.unsqueeze(0)))\n",
    "# rel_s.shape\n",
    "S = rel_s\n",
    "# S = torch.argmax(rel_s,dim =1)\n",
    "s0,s1 = S[:,:,:3,:],S[:,:,3:,:]\n",
    "# torch.argmax(s0,dim =1).numpy()\n",
    "s1 =  s1[:,:,1:-1,1:-1]#reduce\n",
    "s0 = s0[:,:,:,1:-1]# reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_g = RelationTagger(\n",
    "            hidden_size=reduce_size,\n",
    "            n_fields=3,\n",
    "        )\n",
    "\n",
    "rel_g = rel_g(dropout(reduce.unsqueeze(0)))\n",
    "# rel_s.shape\n",
    "G = rel_g\n",
    "# S = torch.argmax(rel_s,dim =1)\n",
    "g0,g1 = G[:,:,:3,:],G[:,:,3:,:]\n",
    "# torch.argmax(s0,dim =1).numpy()\n",
    "g1 =  g1[:,:,1:-1,1:-1]#reduce\n",
    "g0 = g0[:,:,:,1:-1]# reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3106, grad_fn=<NllLoss2DBackward0>) tensor(0.8067, grad_fn=<NllLoss2DBackward0>) tensor(0.6993, grad_fn=<NllLoss2DBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.8166, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = np.array(result['label'])\n",
    "label = torch.tensor(graph[0, :3, :]).unsqueeze(0)\n",
    "matrix_s = torch.tensor(graph[0, 3:, :]).unsqueeze(0)\n",
    "matrix_g = torch.tensor(graph[1, 3:, :]).unsqueeze(0)\n",
    "# label.shape\n",
    "label.shape\n",
    "loss_label_s = loss(s0, label)\n",
    "loss_matrix_s = loss(s1,matrix_s)\n",
    "loss_matrix_g = loss(g1,matrix_g)\n",
    "print(loss_label_s, loss_matrix_s, loss_matrix_g)\n",
    "loss_label_s + loss_matrix_s + loss_matrix_g\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
