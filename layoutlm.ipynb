{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/layoutlm-base-uncased were not used when initializing LayoutLMModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing LayoutLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LayoutLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, BatchEncoding, BertModel,LayoutLMModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/layoutlm-base-uncased\")\n",
    "model = LayoutLMModel.from_pretrained(\"microsoft/layoutlm-base-uncased\")\n",
    "config = AutoConfig.from_pretrained(\"microsoft/layoutlm-base-uncased\")\n",
    "config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# result = json.load(open('./data/raw/truong_raw.jsonl'))\n",
    "# result['boxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "result = json.load(open('./data/processed/huy.jsonl'))\n",
    "result = json.load(open('data/processed/trinh.jsonl'))\n",
    "result = json.load(open('data/processed/kha.jsonl'))\n",
    "result = json.load(open('data/processed/linh.jsonl'))\n",
    "# result = json.load(open('data/processed/trinh.jsonl'))\n",
    "# result = json.load(open('data/processed/trinh.jsonl'))\n",
    "words = result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 93, 90)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(result['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, h = Image.open(result['data_id']).size\n",
    "w,h\n",
    "int(2.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([436, 33, 474, 81],\n",
       " [448, 81, 481, 129],\n",
       " [474, 33, 523, 81],\n",
       " [492, 81, 525, 129],\n",
       " [525, 33, 582, 85],\n",
       " [582, 33, 661, 81],\n",
       " [293, 37, 373, 88],\n",
       " [373, 37, 431, 85],\n",
       " [661, 37, 723, 88],\n",
       " [725, 37, 784, 85],\n",
       " [525, 85, 565, 118],\n",
       " [403, 88, 448, 125],\n",
       " [370, 125, 476, 162],\n",
       " [568, 88, 622, 122],\n",
       " [624, 88, 673, 129],\n",
       " [72, 133, 89, 159],\n",
       " [476, 129, 579, 162],\n",
       " [373, 162, 502, 196],\n",
       " [516, 162, 593, 196],\n",
       " [584, 133, 615, 162],\n",
       " [615, 129, 661, 162],\n",
       " [666, 129, 713, 162],\n",
       " [612, 162, 706, 196],\n",
       " [295, 211, 394, 296],\n",
       " [690, 211, 791, 296],\n",
       " [403, 214, 537, 292],\n",
       " [551, 222, 678, 288],\n",
       " [852, 240, 946, 270],\n",
       " [462, 322, 518, 370],\n",
       " [295, 325, 373, 370],\n",
       " [375, 325, 460, 374],\n",
       " [401, 396, 744, 466],\n",
       " [295, 414, 330, 462],\n",
       " [347, 418, 394, 462],\n",
       " [368, 485, 408, 533],\n",
       " [422, 485, 467, 540],\n",
       " [467, 485, 539, 540],\n",
       " [417, 540, 542, 596],\n",
       " [485, 596, 514, 651],\n",
       " [514, 596, 570, 651],\n",
       " [298, 488, 330, 529],\n",
       " [335, 488, 366, 529],\n",
       " [549, 533, 636, 596],\n",
       " [575, 596, 748, 659],\n",
       " [291, 537, 413, 603],\n",
       " [107, 577, 124, 600],\n",
       " [293, 607, 361, 662],\n",
       " [363, 611, 413, 651],\n",
       " [431, 607, 485, 655],\n",
       " [685, 670, 701, 725],\n",
       " [572, 670, 638, 725],\n",
       " [295, 674, 349, 725],\n",
       " [638, 674, 685, 729],\n",
       " [701, 674, 821, 729],\n",
       " [788, 733, 861, 792],\n",
       " [821, 674, 882, 733],\n",
       " [352, 681, 399, 725],\n",
       " [413, 681, 462, 725],\n",
       " [889, 677, 957, 729],\n",
       " [464, 681, 535, 733],\n",
       " [584, 733, 650, 796],\n",
       " [650, 733, 730, 800],\n",
       " [734, 733, 786, 796],\n",
       " [427, 748, 490, 796],\n",
       " [490, 748, 518, 792],\n",
       " [518, 744, 584, 807],\n",
       " [295, 751, 347, 800],\n",
       " [291, 800, 333, 848],\n",
       " [349, 748, 413, 800],\n",
       " [338, 800, 394, 851],\n",
       " [474, 851, 488, 903],\n",
       " [293, 851, 340, 903],\n",
       " [342, 851, 436, 903],\n",
       " [427, 903, 476, 955],\n",
       " [697, 844, 739, 907],\n",
       " [821, 844, 892, 900],\n",
       " [553, 851, 584, 900],\n",
       " [741, 844, 816, 911],\n",
       " [892, 844, 960, 907],\n",
       " [436, 851, 474, 900],\n",
       " [488, 851, 553, 903],\n",
       " [584, 851, 694, 900],\n",
       " [39, 925, 157, 985],\n",
       " [11, 866, 86, 925],\n",
       " [86, 881, 105, 929],\n",
       " [105, 877, 150, 922],\n",
       " [286, 903, 335, 962],\n",
       " [476, 903, 535, 966],\n",
       " [340, 907, 420, 970],\n",
       " [157, 955, 173, 985])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes = tuple([[ int(x[0][0]*1000/w),int(x[0][1]*1000/h) ,int(x[2][0]*1000/w),int(x[2][1]*1000/h)] for x in result['coord']])\n",
    "# bboxes = tuple(bboxes)\n",
    "bboxes\n",
    "\n",
    "# text label data_id coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [1, 1], [2], [3, 3], [4], [5], [6, 6], [7], [8, 8], [9], [10], [11], [12, 12], [13], [14, 14], [15, 15], [16], [17, 17], [18, 18], [19, 19, 19], [20], [21], [22], [23, 23], [24], [25], [26, 26], [27], [28], [29], [30], [31, 31], [32, 32, 32, 32, 32], [33], [34, 34], [35], [36, 36], [37], [38], [39], [40], [41], [42], [43, 43], [44, 44, 44, 44, 44], [45, 45], [46], [47, 47], [48, 48], [49, 49], [50], [51, 51], [52, 52], [53, 53], [54], [55, 55], [56], [57, 57], [58], [59], [60], [61, 61], [62, 62], [63], [64], [65], [66, 66, 66], [67], [68], [69], [70, 70], [71], [72, 72], [73, 73, 73], [74], [75, 75], [76, 76], [77], [78, 78], [79], [80, 80], [81], [82, 82, 82], [83, 83, 83, 83, 83], [84, 84], [85], [86], [87], [88, 88], [89, 89, 89], [90], [91]]\n",
      "['[CLS]', 'x', '##a', 'lap', 'ho', '##i', 'tu', 'chu', 'ng', '##hia', 'cong', 'ho', '##a', 'viet', 'nam', 'do', 'Ä‘', '##oc', 'socialist', 'han', '##h', 'ph', '##uc', 't', 'he', '##u', 'nguyen', 'nguyen', 'pro', '##cic', '##al', '05', 'viet', 'va', 'hung', 'nam', 'can', 'dan', 'cu', '##oc', 'cong', '-', 'card', 'citizen', 'kin', '##n', '001', '##200', '##01', '##90', '##52', 'so', 'na', '##u', 'ten', 'fu', '##ai', 'name', 'hong', 'of', 'birth', 'ho', 'va', 'lin', '##h', '01', '/', '02', '/', '2000', 'tri', '##nh', 'ma', 'ng', '##ay', 'sin', '##h', 'dat', '##o', '4', 'quo', '##c', 'gi', '##oi', 'ti', '##ch', 'nationality', 'lin', '##h', 'viet', 'tin', '##h', 'sea', 'nam', 'nam', 'lie', '##n', 'mac', ',', 'me', 'place', 'of', 'on', '##g', 'nh', 'quo', 'ha', 'quan', 'no', '##i', '-', 'no', '##i', 'th', '##uo', '##ng', 'ha', 'x', '##a', 'lie', '##n', 'of', 'mac', ',', 'mac', 'tr', '##u', 'place', 'ro', '##si', '##dong', '01', '/', '02', '/', '200', 'co', 'pa', 'v', 'sen', 'me', 'no', '##i', 'lin', '##h', ',', '5', '[SEP]']\n",
      "(148, 4)\n",
      "torch.Size([1, 148, 4])\n",
      "torch.Size([1, 148, 768])\n"
     ]
    }
   ],
   "source": [
    "normalized_word_boxes = bboxes\n",
    "# print(normalized_word_boxes.shape)\n",
    "# words = [\"Hello\", \"world\"]\n",
    "# normalized_word_boxes = [637, 773, 693, 782], [698, 773, 733, 782]\n",
    "encoding = tokenizer(\" \".join(words), return_tensors=\"pt\")\n",
    "token_boxes = []\n",
    "tokens = []\n",
    "tokens = [tokenizer.cls_token] + tokens\n",
    "i =0\n",
    "maps = []\n",
    "maps.extend([[i]])\n",
    "\n",
    "for word, box in zip(words, normalized_word_boxes):\n",
    "    word_tokens = tokenizer.tokenize(word)\n",
    "    token_boxes.extend([box] * len(word_tokens))\n",
    "    tokens.extend(word_tokens)\n",
    "    i += 1\n",
    "    maps.extend([[i]*len(word_tokens)])\n",
    "\n",
    "tokens += [tokenizer.sep_token]\n",
    "maps.extend([[i+1]])\n",
    "# add bounding boxes of cls + sep tokens\n",
    "print((maps))\n",
    "print(tokens)\n",
    "token_boxes = [[0, 0, 0, 0]] + token_boxes + [[1000, 1000, 1000, 1000]]\n",
    "print(np.array(token_boxes).shape)\n",
    "\n",
    "# encoding = tokenizer(\" \".join(words), return_tensors=\"pt\")\n",
    "input_ids = encoding[\"input_ids\"]\n",
    "attention_mask = encoding[\"attention_mask\"]\n",
    "token_type_ids = encoding[\"token_type_ids\"]\n",
    "bbox = torch.tensor([token_boxes])\n",
    "print(bbox.shape)\n",
    "# print(pa['input_ids'].shape, pa['actual_bbox'].shape)\n",
    "# sys.exit()\n",
    "# token_labels = torch.tensor([1, 1, 0, 0]).unsqueeze(0)  # batch size of 1\n",
    "\n",
    "# outputs = model(\n",
    "#     input_ids=pa['input_ids'],\n",
    "#     bbox=tuple(result['boxes']),\n",
    "#     attention_mask=pa['attention_mask'],\n",
    "#     token_type_ids=pa['token_type_ids'],\n",
    "# )\n",
    "outputs = model(\n",
    "    input_ids=input_ids, bbox=bbox, attention_mask=attention_mask, token_type_ids=token_type_ids\n",
    ")\n",
    "\n",
    "# # last_hidden_states = outputs.last_hidden_state\n",
    "# # loss = outputs.loss\n",
    "# # logits = outputs.logits\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "# # loss = outputs.loss\n",
    "# print(outputs.attentions)\n",
    "print(last_hidden_state.shape)\n",
    "# maps[1:-1]``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "reduce_size = 256\n",
    "ln = nn.Linear(config.hidden_size, reduce_size)\n",
    "outputs = ln(last_hidden_state)\n",
    "last_hidden_state = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([92, 256])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "# reduce = torch.zeros(768)\n",
    "reduce =[]\n",
    "for g_token in  maps:\n",
    "    ten = torch.zeros(reduce_size)\n",
    "    for ele in g_token:\n",
    "        # print(ele)\n",
    "        ten += last_hidden_state[0][i]\n",
    "        # i+=1\n",
    "        # print(last_hidden_state[0][i])\n",
    "        i+=1\n",
    "    ten = ten/len(g_token)\n",
    "    # print(ten)\n",
    "    reduce.append(ten)\n",
    "    # reduce = torch.cat((reduce,ten),-1)\n",
    "# print(np.array(reduce).shape)\n",
    "# print(reduce)\n",
    "reduce=  torch.stack(reduce)\n",
    "reduce.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class RelationTagger(nn.Module):\n",
    "    def __init__(self, n_fields, hidden_size, head_p_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.head = nn.Linear(hidden_size, hidden_size)\n",
    "        self.tail = nn.Linear(hidden_size, hidden_size)\n",
    "        self.field_embeddings = nn.Parameter(\n",
    "            torch.rand(1, n_fields, hidden_size))\n",
    "        self.W_label_0 = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.W_label_1 = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "\n",
    "    def forward(self, enc):\n",
    "\n",
    "        enc_head = self.head(enc)\n",
    "        enc_tail = self.tail(enc)\n",
    "\n",
    "        batch_size = enc_tail.size(0)\n",
    "        field_embeddings = self.field_embeddings.expand(batch_size, -1, -1)\n",
    "        enc_head = torch.cat([field_embeddings, enc_head], dim=1)\n",
    "\n",
    "        score_0 = torch.matmul(\n",
    "            enc_head, self.W_label_0(enc_tail).transpose(1, 2))\n",
    "        score_1 = torch.matmul(\n",
    "            enc_head, self.W_label_1(enc_tail).transpose(1, 2))\n",
    "\n",
    "        score = torch.cat(\n",
    "            [\n",
    "                score_0.unsqueeze(1),\n",
    "                score_1.unsqueeze(1),\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        return score\n",
    "\n",
    "\n",
    "dropout = nn.Dropout(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "rel_s = RelationTagger(\n",
    "            hidden_size=reduce_size,\n",
    "            n_fields=3,\n",
    "        )\n",
    "\n",
    "rel_s = rel_s(dropout(reduce.unsqueeze(0)))\n",
    "# rel_s.shape\n",
    "S = rel_s\n",
    "# S = torch.argmax(rel_s,dim =1)\n",
    "s0,s1 = S[:,:,:3,:],S[:,:,3:,:]\n",
    "# torch.argmax(s0,dim =1).numpy()\n",
    "s1 =  s1[:,:,1:-1,1:-1]#reduce\n",
    "s0 = s0[:,:,:,1:-1]# reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_g = RelationTagger(\n",
    "            hidden_size=reduce_size,\n",
    "            n_fields=3,\n",
    "        )\n",
    "\n",
    "rel_g = rel_g(dropout(reduce.unsqueeze(0)))\n",
    "# rel_s.shape\n",
    "G = rel_g\n",
    "# S = torch.argmax(rel_s,dim =1)\n",
    "g0,g1 = G[:,:,:3,:],G[:,:,3:,:]\n",
    "# torch.argmax(s0,dim =1).numpy()\n",
    "g1 =  g1[:,:,1:-1,1:-1]#reduce\n",
    "g0 = g0[:,:,:,1:-1]# reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3106, grad_fn=<NllLoss2DBackward0>) tensor(0.8067, grad_fn=<NllLoss2DBackward0>) tensor(0.6993, grad_fn=<NllLoss2DBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.8166, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = np.array(result['label'])\n",
    "label = torch.tensor(graph[0, :3, :]).unsqueeze(0)\n",
    "matrix_s = torch.tensor(graph[0, 3:, :]).unsqueeze(0)\n",
    "matrix_g = torch.tensor(graph[1, 3:, :]).unsqueeze(0)\n",
    "# label.shape\n",
    "label.shape\n",
    "loss_label_s = loss(s0, label)\n",
    "loss_matrix_s = loss(s1,matrix_s)\n",
    "loss_matrix_g = loss(g1,matrix_g)\n",
    "print(loss_label_s, loss_matrix_s, loss_matrix_g)\n",
    "loss_label_s + loss_matrix_s + loss_matrix_g\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
